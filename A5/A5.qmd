---
format: pdf
editor: visual
execute:
  echo: false
  warning: false
  error: false
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
bibliography: A5.bib
csl: https://www.zotero.org/styles/apa-single-spaced
nocite: |
  | @lecture13, @lecture14
fontsize: 11pt
geometry: 
  - margin = 1in
linestretch: 1.5
---

# Heart failure classification using support vector machine and model based clustering

**STATS/CSE 790 Assignment 5**

**2024-03-19**

**Pao Zhu Vivian Hsu (400547994)**

```{r setup, output=FALSE}
# ----- PACKAGE & DATA SETUP ----- #
library(tidyverse)
library(GGally)
library(e1071)
library(mclust)
library(vscc)
library(kableExtra)

# Load data
heart_raw <- 
  read_csv("/Users/Vivian/Documents/Workspaces/R_Workspace/stats790/A5/heart_failure_clinical_records_dataset.csv")

```

```{r viz-1, output=FALSE}
# ----- DATA TRANSFORMATION ----- #
# Check for missing data
sum(sapply(heart_raw, function(col){ifelse(is.na(col), 1, 0)}))
sum(sapply(heart_raw, function(col){ifelse(sum(col == ""), 1, 0)}))

```

```{r viz-2, output=FALSE}
# Full pairs plot
heartV <- within(heart_raw, death <- ifelse(DEATH_EVENT==1,"Yes", "No"))
ggpairs(data=heartV[,-c(13)], aes(colour=death, alpha=0.4))

```

```{r viz-3, output=FALSE}
# Smaller pairs plot
heartV <- within(heart_raw, death <- ifelse(DEATH_EVENT==1,"Yes", "No"))
ggpairs(data=heartV[, -c(13,6,7,8,9,10,11,12)], aes(colour=death, alpha=0.4))

```

```{r split-1, output=FALSE}
# Split data into train and test
set.seed(790)
heart <- heart_raw
heart[, -13] <- scale(heart_raw[, -13])
train.ind <- sample(1:nrow(heart), nrow(heart) / 2)
heart.train <- heart[train.ind,]
heart.test <- heart[-train.ind,]
heart.test.labs <- heart[-train.ind, "DEATH_EVENT"]

```

```{r linear-1, output=FALSE}
svmfit <- svm(DEATH_EVENT ~ ., data = heart.train, kernel = "linear", 
    cost = 1, scale = FALSE)

summary(svmfit)

```

```{r linear-2, output=FALSE}
# Cross-validation to choose the best cost
set.seed(790)
tune.out <- tune(svm, DEATH_EVENT ~ ., data = heart.train, 
    kernel = "linear", 
    ranges = list(
      cost = c(0.01, 0.1, 0.5, 1, 2, 3, 4, 5, 10, 20)
    )
  )
  
summary(tune.out)
```

```{r linear-3, output=FALSE}
# Prediction
pred <- predict(tune.out$best.model, newdata = heart.test)

tabSvmLinear <- table(pred, heart.test.labs$DEATH_EVENT)

```

```{r radial-1, output=FALSE}
svmfit <- svm(DEATH_EVENT ~ ., data = heart.train, kernel = "radial", gamma = 1, cost = 1)

summary(svmfit)

```

```{r radial-2, output=FALSE}
# Cross-validation to choose the best gamma and cost
set.seed(790)
tune.out <- tune(svm, DEATH_EVENT ~ ., data = heart.train, 
    kernel = "radial", 
    ranges = list(
      cost = c(1, 5, 6, 7, 8, 9, 10, 15, 20, 30),
      gamma = c(1, 2, 3, 4, 5, 6, 8, 10, 15, 20)
    )
  )
  
summary(tune.out)
```

```{r radial-3, output=FALSE}
# Prediction
pred <- predict(tune.out$best.model, newdata = heart.test)

tabSvmRadial <- table(pred, heart.test.labs$DEATH_EVENT)

```

```{r svm-summary, output = FALSE}
# RESULTS
method <- c("SVM Linear Kernel", "SVM Radial Kernel")
crand <- c(classAgreement(tabSvmLinear)$crand,
           classAgreement(tabSvmRadial)$crand)
misclass <- c(1-classAgreement(tabSvmLinear)$diag, 
              1-classAgreement(tabSvmRadial)$diag)
summary <- data.frame("Method" = method, 
                      "Adjusted Rand Index" = round(crand,5),
                      "Misclassification Error Rate" = round(misclass,5),
                      check.names = FALSE)
kable(summary)

```

```{r cluster-mclust-1, output = FALSE}
# MCLUST
x <- scale(heart[,-13])
modclust <- Mclust(x, 2)
summary(modclust)

```

```{r cluster-mclust-2, output = FALSE}
tabFull <- table(class=heart$DEATH_EVENT, 
                 predictions=factor(as.character(map(modclust$z)-1)))

```

```{r cluster-vscc-1, output = FALSE}
# VSCC
x <- scale(heart[,-13])
modvscc <- vscc(x)
tabReduced <- table(class=heart$DEATH_EVENT,
                    predictions=modvscc$bestmodel$classification)

```

```{r cluster-vscc-2, output = FALSE}
# Show selected variables
head(modvscc$topselected)
plot(modvscc)

```

```{r cluster-summary, output = FALSE}
# RESULTS
method <- c("Full Model", "Reduced Model")
crand <- c(classAgreement(tabFull)$crand,
           classAgreement(tabReduced)$crand)
misclass <- c(1-classAgreement(tabFull)$diag, 
              1-classAgreement(tabReduced)$diag)
summary <- data.frame("Method" = method,
                      "Adjusted Rand Index" = round(crand,5),
                      "Misclassification Error Rate" = round(misclass,5),
                      check.names = FALSE)
kable(summary)

```

## Introduction

In this study, we use Support Vector Machines (SVMs) and model based clustering to predict mortality attributed to heart failure. The data in this study comes from an open sourced website called Kaggle [@heartDataset]. It contains 299 rows of patient data and 13 variables of measurements. The response variable is a binary categorical variable indicating the event of death. The remaining variables include age, anaemia, creatinine phosphokinase, diabetes, ejection fraction, high blood pressure, platelets, serum creatinine, serum sodium, sex, smoking, and time.

## Methods

We start the study by checking the shape of the data and ensuring there are no missing values. We then visualized the data in a pairs plot to check for any patterns in the data. @fig-pairs shows a subset of this plot, where blue indicates a positive mortality case and red indicates a negative one. We can see that the observations have a non-linear boundary between them, which makes the data suitable for SVM or model based clustering.

As such, we then split the data into two equal parts to form training and testing sets and applied these two different techniques to the data: SVM and model based clustering.

```{r fig-pairs, ref.label="viz-3", output=TRUE, message=FALSE, fig.cap="Pairs plot of a selection of the variables", fig.height=3, fig.width=5}
```

The first technique was SVM, a supervised learning method that uses non-linear decision boundaries to classify data. The boundaries are defined using a kernel function which is used to enlarge the feature space and measure the similarity between observations. For our study, we used linear and radial kernels to model the data. The linear kernel is defined as $K(x_i, x_i\prime) = \sum_{j=1}^{p}x_{ij},x_i\prime_{j}$ and the radial kernel is defined as $K(x_i, x_i\prime) = exp(-\gamma\sum_{j=1}^{p}(x_{ij}-x_i\prime_{j})^2)$ where $\gamma$ is a positive constant and $i$ represents the $i$th observation [@lecture14].

We used cross validation to tune the cost parameter C and gamma constant $\gamma$. The cost parameter measures the number of observations that can be on the wrong side of the hyperplane and the tolerance towards margin violations. In other words, it puts a limitation on the sum of slack variables $\epsilon_i$ where $\epsilon_i$ indicates whether the $i$th observation is on the correct side of the margin ($\epsilon_i = 0$) or violates the margin ($\epsilon_i > 0$). Thus, C controls the bias and variance in the model which we seek to optimize [@lecture13]. For the linear kernel, we tried 10 different values of the cost parameter and found 0.1 to be the optimal value. For the radial kernel, we tried 10 different values of the cost parameter and found 5 to be the optimal value. Likewise, we tried 10 different values of gamma and found 3 to be the optimal value.

After cross-validation, the models were then fit using the test set and results were recorded.

The second technique we applied to the data was model based clustering. The first model contained all 13 predictor variables. The second model contained only 2 predictor variables.

## Results

@tbl-svm-summary below summarizes the SVM results using linear and radial kernels. The adjusted Rand index (ARI) is very poor for both kernels despite cross-validation. The ARI is slightly higher for the radial kernel compared to the linear kernel indicating that a radial kernel may be a better fit. We see a similar pattern for the misclassification error rate where the performance is better for the radial kernel compared to the linear kernel.

```{r}
#| label: tbl-svm-summary
#| ref-label: svm-summary
#| tbl-cap: SVM performance comparison
#| output: TRUE
#| message: FALSE
```

@tbl-cluster-summary below summarizes the model based clustering results using a full and reduced model. The adjusted Rand index (ARI) is very poor for both kernels despite cross-validation. The ARI is slightly higher for the radial kernel compared to the linear kernel indicating that a radial kernel may be a better fit. We see a similar pattern for the misclassification error rate where the performance is better for the radial kernel compared to the linear kernel.

```{r}
#| label: tbl-cluster-summary
#| ref-label: cluster-summary
#| tbl-cap: Model based clustering performance comparison
#| output: TRUE
#| message: FALSE
```

## Conclusion

Overall, our study shows that applying SVM to heart disease

Overall, our study shows that applying PCA prior to clustering for diabetes classification is not very effective. A few ways to improve the accuracy of these models include feature engineering, performing more extensive data cleansing prior to modelling, and incorporating subject-matter expertise when interpreting results.

## References

::: {#refs}
:::

\newpage

## Appendix

```{r report-code, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
